students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE)
submit()
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread( test, test) %>%
print
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread( test, grade) %>%
print
submit()
extract_numeric("class5")
extract_numeric("class509r33")
?mutate
submit()
submit()
submit()
submit()
submit()
submit()
students4
submit()
submit()
submit()
submit()
passed
failed
mutate(passed, status = "passed")
passed <- mutate(passed, status = "passed")
failed <- failed %>% mutate(passed, status = "failed")
failed <- failed %>% mutate(status = "failed")
?rbind_list
rbind_list(passed, failed)
sat
?select
sat %>%
select(-contains("total"))
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range)
?separate
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex, c("male", "fem"))> %>%
print
sat %>%
select(-contains("total"))
sat
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range)
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex, c("part", "sex"))>
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex, c("part", "sex"))
submit()
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex, c("part", "sex")) %>%
group_by(part, sex)> %>%
mutate(total = sum(count),
prop = count / total
)
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex, c("part", "sex")) %>%
group_by(part, sex)
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex, c("part", "sex")) %>%
group_by(part, sex) %>%
mutate(total = sum(count),
prop = count / total
)
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
hour(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
ymd("March 12, 1975")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dr1
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 22, minutes = 57)
this_moment
?now
nyc <- now(tzone = "America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(nyc, hours = 17, minutes = 34)
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- update(depart, hours = 15, minutes = 50)
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?new_interval
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
library(xlsx)
install.packages("xlsx")
library(xlsx)
# install.packages("xlsx")
library(xlsx)
colIndex <- 7:15
rowIndex <- 18:23
dat <- read.xlsx("C://Users//reza.GTOWER//Documents//Coursera//Getting and Cleaning Data//Quizes//Week 001//getdata-data-DATA.gov_NGAP.xlsx", sheetIndex = 1, colIndex = colIndex, rowIndex = rowIndex)
head(dat)
# install.packages("xlsx")
library(xlsx)
colIndex <- 7:15
rowIndex <- 18:23
dat <- read.xlsx("C://Users//reza.GTOWER//Documents//Coursera//Getting and Cleaning Data//Quizes//Week 001//getdata-data-DATA.gov_NGAP.xlsx", sheetIndex = 1, colIndex = colIndex, rowIndex = rowIndex)
sum(dat$Zip*dat$Ext,na.rm=T)
install.packages("xml")
install.packages("XML")
rm(ls=list())
rm(list=ls())
# Read the XML data on Baltimore restaurants from here:
#
# https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
#
# How many restaurants have zipcode 21231?
# install.packages("XML")
library(XML)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml "
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
# Read the XML data on Baltimore restaurants from here:
#
# https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
#
# How many restaurants have zipcode 21231?
# install.packages("XML")
library(XML)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
# Read the XML data on Baltimore restaurants from here:
#
# https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
#
# How many restaurants have zipcode 21231?
# install.packages("XML")
library(XML)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
# Read the XML data on Baltimore restaurants from here:
#
# https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
#
# How many restaurants have zipcode 21231?
# install.packages("XML")
library(XML)
# fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
fileUrl <- "C://Users//reza.GTOWER//Documents//Coursera//Getting and Cleaning Data//Quizes//Week 001//getdata_data_restaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
# Read the XML data on Baltimore restaurants from here:
#
# https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
#
# How many restaurants have zipcode 21231?
# install.packages("XML")
library(XML)
# fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
fileUrl <- "C://Users//reza.GTOWER//Documents//Coursera//Getting and Cleaning Data//Quizes//Week 001//getdata_data_restaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
xpathSApply(rootNode, "//zipcode", xmlvalue)
xpathSApply(rootNode, "//zipcode", xmlValue)
xpathSApply(rootNode, "//zipcode=21231", xmlvalue)
xpathSApply(rootNode, "//zipcode=21231", xmlValue)
xpathSApply(rootNode, "//zipcode[text() = '21231']", xmlValue)
count(xpathSApply(rootNode, "//zipcode[text() = '21231']", xmlValue))
length(xpathSApply(rootNode, "//zipcode[text() = '21231']", xmlValue))
tables()
table()
# install.packages("data.table")
install.packages("data.table")
library(data.table)
DT <- fread("C://Users//reza.GTOWER//Documents//Coursera//Getting and Cleaning Data//Quizes//Week 001//getdata-data-ss06pid.csv")
DT[,mean(pwgtp15),by=SEX]
mean(DT$pwgtp15,by=DT$SEX)
sapply(split(DT$pwgtp15,DT$SEX),mean)
tapply(DT$pwgtp15,DT$SEX,mean)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
system.time({DT[,mean(pwgtp15),by=SEX]})
library(RMySQL)
myDBConnection <- dbConnect(MySQL(), user="root", password="41-BD-20-F5-91-FF-az", host="localhost")
result <- dbGetQuery(myDBConnection, "show databases;"); dbDisconnect(myDBConnection);
result
myDBConnection <- dbConnect(MySQL(), user="root", password="41-BD-20-F5-91-FF-az", db="sakila", host="localhost")
allTables <- dbListTables(myDBConnection)
allTables
dbListFields(myDBConnection, "actor")
dbGetQuery(myDBConnection, "select count(*) from actor")
dbClearResult(result)
dbDisconnect(myDBConnection)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
create = h5createFile("example.h5")
rm(create)
created = h5createFile("example.h5")
created = h5createGroup("example.h5","foo")
created = h5createGroup("example.h5","baa")
created = h5createGroup("example.h5","foo/foobaa")
h5ls("example.h5")
A <- matrix(1:10,nr=5,nc=2)
h5write(A, "example.h5","foo/A")
B <- array(seq(0.1,2.0,by=0.1),dim=c(5,2,2))
attr(B, "scale") <- "liter"
h5write(B, "example.h5","foo/foobaa/B")
h5ls("example.h5")
df = data.frame(1L:5L,seq(0,1,length.out=5),c("ab","cde","fghi","a","s"), stringsAsFactors=FALSE)
h5write(df, "example.h5", "df")
h5ls("example.h5")
readdf <- h5read("example.hf","df")
readdf <- h5read("example.h5","df")
readdf
?nchar
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(con)
length(con)
length(htmlCode)
nchar(htmlcode[c(10,20,30,100)])
nchar(htmlCode[c(10,20,30,100)])
close(con)
close(con)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(con)
nchar(htmlCode[c(10,20,30,100)])
close(con)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "56b637a5baffac62cad9")
?oauth_app
myapp <- oauth_app("github", "c80b7bcc18098500f579", "a085229276e1db21c9260bc88451306d4c9874ee")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
rm(ls=list())
rm(list=ls())
librar(sqldf)
library(sqldf)
library("sqldf")
package.install("sqldf")
install.package("sqldf")
install.packages("sqldf")
library("sqldf")
asc <- GET("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
librar(httr)
library(httr)
asc <- GET("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
?sqldf
class(asc)
?read.csv
df <- read.csv(asc)
rm(asc)
asc <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
class(asc)
sqldf("select pwgtp1 from acs where AGEP < 50")
install.packages("tcltk")
install.packages("tcltk")
install.packages("tcltk")
sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
sqldf("select pwgtp1 from acs where AGEP < 50")
?tcltk
sqldf("select pwgtp1 from acs where AGEP < 50")
asc <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
sqldf("select pwgtp1 from acs where AGEP < 50")
rm asc
rm(asc)
acs <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select distinct AGEP from acs")
?read.table
fortran_file <- "C://Users//reza.GTOWER//Documents//Coursera//Getting and Cleaning Data//Quizes//Week 002//getdata-wksst8110.for"
ff <- read.fortran(fortran_file)
# original source http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for
x <- read.fwf(
file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(x)
class(x)
head(x$V1)
head(x$V2)
sum(x$V4+x$V9)
sum(x$V4)
sum(x$V9)
32426.7 + 36.5
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
??gplot
??gplot2
??ggplot2
??ggplot
?geom
library(ggplot2)
packages.install("ggplot2")
install.packages("ggplot2")
library(ggplot2)
?geom
??geom
library(lattice)
?xplot
?xyplot
library(lattice)
library(datasets)
xyplot(Ozone ~ Wind, data = airquality)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?par
?splom
?trellis.par.set
?print.trellis
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
?ggplot
?aes
?geom
??geom
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
?weekdays
activity_dt <- data.table(read.csv("activity.csv"))
library(data.table)
activity_dt <- data.table(read.csv("activity.csv"))
activity_na_dt <- activity_dt[!complete.cases(activity_dt)]
lookup_avg_step <- function (n_interval) { interval_steps_dt$total_daily_steps[interval_steps_dt$interval == n_interval] }
activity_na_dt$steps = sapply(activity_na_dt$interval, lookup_avg_step)
activity_ok_dt <- activity_dt[complete.cases(activity_dt)]
activity_cleaned_dt <- rbind(activity_ok_dt, activity_na_dt)[order(date, interval)]
rm(list = ls())
activity_dt <- data.table(read.csv("activity.csv"))
setwd("C://Users//reza.GTOWER//Documents//Coursera//DataScience_005_Reproducible_Research//Assignment_1//GitHub//RepData_PeerAssessment1")
activity_dt <- data.table(read.csv("activity.csv"))
activity_na_dt <- activity_dt[!complete.cases(activity_dt)]
lookup_avg_step <- function (n_interval) { interval_steps_dt$total_daily_steps[interval_steps_dt$interval == n_interval] }
activity_na_dt$steps = sapply(activity_na_dt$interval, lookup_avg_step)
interval_steps_dt <- activity_dt[,list(total_daily_steps=sum(steps, na.rm = TRUE)),by=interval]
activity_na_dt$steps = sapply(activity_na_dt$interval, lookup_avg_step)
activity_ok_dt <- activity_dt[complete.cases(activity_dt)]
activity_cleaned_dt <- rbind(activity_ok_dt, activity_na_dt)[order(date, interval)]
daily_activity_dt <- activity_cleaned_dt[,list(total_daily_steps=sum(steps, na.rm = TRUE)),by=date]
str(daily_activity_dt)
str(activity_cleaned_dt)
head(weekday(activity_cleaned_dt$date))
head(weekdays(activity_cleaned_dt$date))
?as.date
head(weekdays(as.Date(activity_cleaned_dt$date))
)
head(weekdays(as.Date(activity_cleaned_dt$date)))
head(activity_cleaned_dt$date)
head(weekdays(as.Date(activity_cleaned_dt$date, "%Y-%m-%d")))
class(activity_dt%date)
class(activity_dt$date)
?is.NA
?is.na
lookup_avg_step <- function (n_interval, n_steps) {
if (is.na(n_steps))
interval_steps_dt$total_daily_steps[interval_steps_dt$interval == n_interval]
else
n_steps
}
lookup_avg_step <- function (n_interval, n_steps) {
print length(n_steps)
if (is.na(n_steps))
interval_steps_dt$total_daily_steps[interval_steps_dt$interval == n_interval]
else
n_steps
}
?len
?size
?count
lookup_avg_step <- function (n_interval, n_steps) {
print count(n_steps)
if (is.na(n_steps))
interval_steps_dt$total_daily_steps[interval_steps_dt$interval == n_interval]
else
n_steps
}
print (2)
lookup_avg_step <- function (n_interval, n_steps) {
print length(n_steps)
if (is.na(n_steps) == TRUE) {
interval_steps_dt$total_daily_steps[interval_steps_dt$interval == n_interval
}
else {
n_steps
}
}
lookup_avg_step <- function (n_interval, n_steps) { print length(n_steps) if (is.na(n_steps) == TRUE) { interval_steps_dt$total_daily_steps[interval_steps_dt$interval == n_interval }
else {n_steps
}
}
lookup_avg_step <- function (n_interval, n_steps) {
# print length(n_steps)
if (is.na(n_steps) == TRUE) {
interval_steps_dt$total_daily_steps[interval_steps_dt$interval == n_interval
}
else {
n_steps
}
}
lookup_avg_step <- function (n_interval, n_steps) {
# print length(n_steps)
if (is.na(n_steps) == TRUE)
interval_steps_dt$total_daily_steps[interval_steps_dt$interval == n_interval
else
n_steps
}
lookup_avg_step <- function (n_interval, n_steps) {
# print length(n_steps)
if (is.na(n_steps) == TRUE)
interval_steps_dt$total_daily_steps[interval_steps_dt$interval == n_interval
else
n_steps
}
clear
cls
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
activity_impute_dt <- data.table(activity_dt)
activity_impute_dt$steps = lookup_avg_step(activity_dt$interval, n_steps = activity_dt$steps)
lookup_avg_step(activity_dt$interval, n_steps = activity_dt$steps)
View(activity_cleaned_dt)
is_week_day <- function(d_day) {
if (weekdays(d_day) %in% c("Saturday", "Sunday") )
"weekend"
else
"weekday"
}
activity_cleaned_dt["day_type"] <- as.factor(is_week_day(activity_cleaned_dt$date))
weekdays(activity_cleaned_dt$date)
class(activity_cleaned_dt$date)
class(as.Date(activity_cleaned_dt$date)
)
weekdays(as.Date(activity_cleaned_dt$date))
activity_cleaned_dt["day_type"] <- as.factor(is_week_day(as.Date(activity_cleaned_dt$date)))
cnames(activity_cleaned_dt)
colnames(activity_cleaned_dt)
activity_cleaned_df <- data.frame(activity_cleaned_dt)
dates <- as.Date(activity_cleaned_df$date)
activity_cleaned_df["day_type"] <- as.factor(sapply(dates, is_week_day))
colnames(activity_cleaned_df)
str(activity_cleaned_df)
head(activity_cleaned_df)
subset(activity_cleaned_df, intervale == 0)
subset(activity_cleaned_df, interval == 0)
head(activity_cleaned_df)
subset(activity_cleaned_df, day_type == "weekday")
subset(activity_cleaned_df, day_type == "weekend")
clear
cls
